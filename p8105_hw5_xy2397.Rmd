---
title: "p8105_hw5_xy2397"
author: "Xue Yang"
date: "11/2/2018"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(rvest)


knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_bw() + theme(legend.position = "bottom"))

set.seed(1)
```


## Problem 1


### Create a tidy dataframe 


```{r, message = FALSE}
study = 
  
  # start with a dataframe containing all file names
  tibble(file_name = list.files(path = "./data/pro1")) %>% 
  
  # iterate over file names and read in data for each subject
  mutate(output = purrr::map(str_c("./data/pro1/", file_name), read_csv)) %>%
  
  # unnest the dataframe
  unnest() %>% 
  
  # separate the file name with arm and subject id
  mutate(file_name = str_replace(file_name, ".csv", "")) %>% 
  separate(file_name, into = c("arm", "subject_id"), sep = "_") %>% 
  mutate(arm = str_replace(arm, "con", "control"),
         arm = str_replace(arm, "exp", "experimental")) %>% 
  
  # gather the week and observations
  gather(key = "week", value = "observation", week_1:week_8) %>% 
  
  # do some other tidy
  mutate(week = str_replace(week, "week_", "")) %>% 
  arrange(subject_id)

study %>% 
  head() %>% 
  knitr::kable(digits = 3)
  
```

### Make a spaghetti plot

```{r}
# a spaghetti plot showing observations on each subject over time
study %>% 
  ggplot(aes(x = week, y = observation)) +
  geom_line(aes(group = subject_id, color = subject_id)) +
  facet_grid(~arm) +
  labs(
    title = "Spaghetti plot",
    x = "Week",
    y = "Observations"
  ) + 
  viridis::scale_color_viridis(
    name = "Subject ID",
    discrete = TRUE
    ) 

  
```

### Comment on differences between groups

By looking at the observations from spaghetti plot between control arm and experimental arm, we can find that there are significantly increasing trend on each subject over time in the observations form experimental arm but there aren't significantly increasing trend in control arm.


## Problem 2

```{r, message = FALSE}
# load the data
homicide = 
  read_csv(file = "./data/pro2/homicide-data.csv") 
```

### Describe the raw data

The data is `r nrow(homicide)` rows x `r ncol(homicide)` columns, which means that there are `r nrow(homicide)` observations of criminal homicides in `r length(unique(homicide$city))` of the largest American cities. We are major interested in the variables like the location of criminal homicides (city and state) and disposition of the homicides (solved or unsolved).


### Summarize the data

Create a city_state variable (e.g. “Baltimore, MD”) 

```{r}
homicide = 
  homicide %>% 
  # create a city_state variabl
  unite(city_state, city, state, sep = ",") 
```

Summarize within cities to obtain the total number of homicides and the number of unsolved homicides (those for which the disposition is “Closed without arrest” or “Open/No arrest”).

```{r}
total = 
  homicide %>% 
  group_by(city_state) %>% 
  summarize(number = n()) %>% 
  unnest()

unsolved = 
  homicide %>%   
  filter(disposition %in% c("Closed without arrest", "Open/No arrest")) %>%
  group_by(city_state) %>% 
  summarize(number_unsolved = n()) %>% 
  unnest() 
```

The following tables are the total number of homicides and the number of unsolved homicides within each city. 


```{r}
total %>% 
  knitr::kable(digits = 3)

unsolved %>% 
  knitr::kable(digits = 3)
  
```

Noting that "Tulsa,AL" doesn't have unsolved homicides. There only exist one homicide report in "Tulsa,AL", which is solved. Also city "Tulsa" also exist in the state "OK", which contains 583 reports including solved and unsolved. It is a little bit weird. So for the following analysis, we delete the report in "Tulsa,AL" to make sure we can calculate the proportion of unsloved homicides in every city.

```{r}
homicide %>%   
  filter(city_state == "Tulsa,AL") %>% 
  select(uid, reported_date, city_state, disposition) %>% 
  knitr::kable(digits = 3)

homicide %>%   
  count(city_state) %>% 
  filter(city_state %in% c("Tulsa,AL", "Tulsa,OK")) %>% 
  knitr::kable(digits = 3)
```

### Estimate the proportion of unsolved homicides

For the city of Baltimore, MD, use the prop.test function to estimate the proportion of homicides that are unsolved; save the output of prop.test as an R object, apply the broom::tidy to this object and pull the estimated proportion and confidence intervals from the resulting tidy dataframe.

```{r}
# total number of homicides
n =
  total %>% 
  filter(city_state == "Baltimore,MD") %>% 
  pull(number)

# number of unsolved homicides
x =
  unsolved %>% 
  filter(city_state == "Baltimore,MD") %>% 
  pull(number_unsolved)

# save the output of prop.test as an R object
result = 
  prop.test(x, n, alternative = "two.sided") %>% 
  broom::tidy() 

#  pull the estimated proportion and confidence intervals
results = 
  tibble(
    
    city = "Baltimore,MD",
    
  estimated_proportion = 
    result %>% 
    pull(estimate),
  
  conf_low = 
    result %>% 
    pull(conf.low),
  
  conf_high = 
    result %>% 
    pull(conf.high)
  )

results %>% 
  knitr::kable(digits = 3)
  
```


Now run prop.test for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each. Do this within a “tidy” pipeline, making use of purrr::map, purrr::map2, list columns and unnest as necessary to create a tidy dataframe with estimated proportions and CIs for each city.

```{r}

# create a function to do the prop.test in each city
proportion_test = function(city){
  n =
  total %>% 
  filter(city_state == city) %>% 
  pull(number)
  
  x =
  unsolved %>% 
  filter(city_state == city) %>% 
  pull(number_unsolved)
  
  result = prop.test(x, n, alternative = "two.sided")
  
  broom::tidy(result) 
  
}

output = 
  tibble(city = unsolved$city_state) %>% 
  mutate(estimate = purrr::map(.x = unsolved$city_state, ~proportion_test(city = .x))) %>%
  unnest() %>% 
  select(city,
         estimated_proportion = estimate,
         conf.low, 
         conf.high)

output %>% 
  knitr::kable(digits = 3)

```

As what we discussed above, since the city "Tulsa,AL" don't have unsolved homicides, so when dealing with the proportion of unsolved homicides and the confidence interval for each, we only concentrate on the left 50 cities that contains both solved and unsolved homicides.

### Create a plot

Create a plot that shows the estimates and CIs for each city – check out geom_errorbar for a way to add error bars based on the upper and lower limits. Organize cities according to the proportion of unsolved homicides.

```{r}
output %>% 
  # reorder the city as the increase of median of estimated_proportion
  mutate(city = forcats::fct_reorder(city, estimated_proportion)) %>% 
  ggplot(aes(x = city, y = estimated_proportion, color = city)) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  labs(
    title = "Estimates and CIs for City",
    x = "City",
    y = "Estimates and CIs"
  ) +
  viridis::scale_color_viridis(
    name = "City",
    discrete = TRUE
  ) +
  theme(legend.position = "none") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) 
  
```

From the plot above, we can conclude that city "Richmond, VA" has the lowest proportion of unsolved homicides, while city "Chicago,IL" has the highest unsolved proportion of unsolved homicides. "Nwe York, NY" is ranking 13 lowest city.